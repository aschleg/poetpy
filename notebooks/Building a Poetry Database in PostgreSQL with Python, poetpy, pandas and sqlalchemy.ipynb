{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [PoetryDB API](https://github.com/thundercomb/poetrydb/blob/master/README.md) stores its data in [MongoDB](https://www.mongodb.com/), a popular [NoSQL database](https://en.wikipedia.org/wiki/NoSQL). Indeed, a NoSQL database is a solid choice for the type of data that is stored in PoetryDB (unstructured text, for example). However, what if we wanted to create a more traditional SQL database with the PoetryDB API data for use in other projects where a relational database would be preferred? By extracting the data from the PoetryDB API using a combination of a few Python libraries, we can recreate the NoSQL PoetryDB database as a SQL database which will allow us more freedom to create additional data features and avoid the need to hit the PoetryDB database more than necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we walk through a sample use case of extracting data from a database using an API and then structuring that data in a cohesive manner that allows us to create a relational database that we can then query with SQL statements. The database we will create with the extracted data will use [Postgresql](https://www.postgresql.org/).\n",
    "\n",
    "The Python libraries that will be used in this example are [poetpy](https://github.com/aschleg/poetpy), a Python wrapper for the PoetryDB API written by yours truly, [pandas](https://pandas.pydata.org/) for transforming and cleansing the data as needed, and [sqlalchemy](https://www.sqlalchemy.org/) for handling the SQL side of things. We start by importing the needed libraries as per usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from poetpy import get_poetry\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "import sqlalchemy\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the Poetry Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can't have a useful database without any data! Before beginning to hit any API, it is often useful to devise a strategy for getting the wanted data in an efficient manner that avoids requesting the API more than needed. According to the [PoetryDB API documentation](https://github.com/thundercomb/poetrydb/blob/master/README.md), we can get a list of authors which we can then use to iterate over to get each author's poetry and other available information from the database.\n",
    "\n",
    "We can use the `poetpy` function `get_poetry` to return a dictionary object of the available authors in the PoetryDB database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = get_poetry('author')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The returned dictionary contains a list of the available authors, which we can quickly inspect to make sure our API call was successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Adam Lindsay Gordon',\n",
       " 'Alan Seeger',\n",
       " 'Alexander Pope',\n",
       " 'Algernon Charles Swinburne',\n",
       " 'Ambrose Bierce']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors['authors'][0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To store the extracted authors for later exporting into a flat-file such as a CSV and loading into a database, we convert the returned dictionary into a [pandas DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html) using the [`from_dict`](https://pandas.pydata.org/pandas-docs/version/0.22/generated/pandas.DataFrame.from_dict.html) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_df = pd.DataFrame.from_dict(authors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a list of authors to iterate over, we can extract the remaining data from the PoetryDB database! For each of the authors in the database, we extract the titles, content, and linecounts of their poetry, normalize the returned JSON into a `DataFrame` with `pandas`'s handy [`json_normalize`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.io.json.json_normalize.html) function and append the resulting data to a list. After each author in the list has been iterated over, the list with the appended results are then concatenated into one `DataFrame` with the [`pd.concat`](https://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.concat.html) function. This operation will give us a complete dataset of all the available information in the PoetryDB API as a pandas `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "poems = []\n",
    "for author in authors['authors']:\n",
    "    author_poems = get_poetry('author', author, 'author,title,lines,linecount')\n",
    "    author_poems_df = json_normalize(author_poems)\n",
    "    poems.append(author_poems_df)\n",
    "    \n",
    "poems_df = pd.concat(poems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PoetryDB API data is now collected into one `DataFrame`! We can inspect the first few rows of the `DataFrame` to see the resulting data that was returned with the [`head`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.head.html) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>linecount</th>\n",
       "      <th>lines</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adam Lindsay Gordon</td>\n",
       "      <td>16</td>\n",
       "      <td>[‘WHERE shall we go for our garlands glad, At ...</td>\n",
       "      <td>A Song of Autumn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adam Lindsay Gordon</td>\n",
       "      <td>56</td>\n",
       "      <td>[The ocean heaves around us still, With long a...</td>\n",
       "      <td>An Exile's Farewell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alan Seeger</td>\n",
       "      <td>24</td>\n",
       "      <td>[I have a rendezvous with Death, At some dispu...</td>\n",
       "      <td>I Have A Rendezvous With Death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alan Seeger</td>\n",
       "      <td>104</td>\n",
       "      <td>[I, , Ay, it is fitting on this holiday,, Comm...</td>\n",
       "      <td>Ode in Memory of the American Volunteers Falle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alan Seeger</td>\n",
       "      <td>83</td>\n",
       "      <td>[In that fair capital where Pleasure, crowned,...</td>\n",
       "      <td>Fragments</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                author linecount  \\\n",
       "0  Adam Lindsay Gordon        16   \n",
       "1  Adam Lindsay Gordon        56   \n",
       "0          Alan Seeger        24   \n",
       "1          Alan Seeger       104   \n",
       "2          Alan Seeger        83   \n",
       "\n",
       "                                               lines  \\\n",
       "0  [‘WHERE shall we go for our garlands glad, At ...   \n",
       "1  [The ocean heaves around us still, With long a...   \n",
       "0  [I have a rendezvous with Death, At some dispu...   \n",
       "1  [I, , Ay, it is fitting on this holiday,, Comm...   \n",
       "2  [In that fair capital where Pleasure, crowned,...   \n",
       "\n",
       "                                               title  \n",
       "0                                   A Song of Autumn  \n",
       "1                                An Exile's Farewell  \n",
       "0                     I Have A Rendezvous With Death  \n",
       "1  Ode in Memory of the American Volunteers Falle...  \n",
       "2                                          Fragments  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poems_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see each value in the `lines` column of the `DataFrame` is still a list of strings that comprise the particular poem. To edit the `lines` column to extract the poetry lines, we can use the [`apply`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.apply.html) method to apply a `lambda` function over each row in the `DataFrame` to join each string in the list as one string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "poems_df['lines'] = poems_df['lines'].apply(lambda x: ' \\n '.join(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the first couple rows of the `lines` column to ensure the operation returned what we expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ‘WHERE shall we go for our garlands glad \\n At...\n",
       "1    The ocean heaves around us still \\n With long ...\n",
       "Name: lines, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poems_df['lines'].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the data extracted from the PoetryDB database and transformed into a tabular data structure, we then save the datasets into a csv file using the [`to_csv`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_csv.html) method. The exported csv files will be used to insert the data into our Postgresql database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "poems_df.to_csv('../data/poetrydb_copy.csv', index=False, encoding='utf-8')\n",
    "authors_df.to_csv('../data/poetrydb_authors.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Postgresql database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The installation of Postgresql is beyond the scope of this example; however, there is a handy [tutorial](http://www.postgresqltutorial.com/install-postgresql/) available which details the steps for installing Postgresql for particular operating systems.\n",
    "\n",
    "During the installation of Postgresql, a `postgres` database is created that we can use for testing our relational database. Postgresql works slightly different than other SQL engines in that it employs the concept of [schemas](https://www.postgresql.org/docs/8.1/static/ddl-schemas.html) for managing data, which in other types of SQL would be a database. The installation will prompt the user to create a master username and password, which we will use to connect to the localhost `postgres` database.\n",
    "\n",
    "This is the section of the example where SQLAlchemy comes into play. The first step in connecting to a database with SQLAlchemy is to employ the [`create_engine`](http://docs.sqlalchemy.org/en/latest/core/engines.html) function. According to the function's documentation, the `create_engine` function takes a string parameter that details the connection info based on the following structure:\n",
    "\n",
    "```terminal\n",
    "dialect+driver://username:password@host:port/database\n",
    "```\n",
    "\n",
    "Where `dialect` is a SQL engine such as `postgresql`, `mysql`, `mssql`, and so on. Thus, we use the newly created `postgres` database along with the username and password specified during the installation of `Postgresql`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = sqlalchemy.create_engine('postgresql://postgres:root@localhost:5432/postgres')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `engine` variable is then used to create the connection to the `postgres` database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = engine.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now begin working with the `Postgresql` database and insert our extracted data! The first step is to create a [schema](https://www.postgresql.org/docs/8.1/static/ddl-schemas.html) which we will use as our local database for testing purposes. Using our database connection, we can send a query to the `postgres` database to create a schema using the `CREATE SCHEMA` statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.result.ResultProxy at 0x10850b128>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.execute('CREATE SCHEMA poetry')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output indicates the operation was successful! The next step is to create the necessary schema tables and load the data we extracted earlier from the PoetryDB API into those tables. There are several approaches to creating the tables and loading the data into those tables. One approach and typically the most general way to load data into Postgresql is to create the tables and then load a flat file such as a csv into the tables using the `psql` command line. Another approach is using `pandas` and `SQLAlchemy` to load the data directly from a `DataFrame` into a Postgresql database or schema.\n",
    "\n",
    "As the last step before loading the data, let's use our `SQLAlchemy` connection to the database to create the tables that we will use to store our data. For more extended SQL statements, it can be a good idea to write out the statement or query as a multi-line string for clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.result.ResultProxy at 0x10850b518>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_author_table = '''\n",
    "CREATE TABLE poetry.authors\n",
    "(\n",
    "    id serial PRIMARY KEY, \n",
    "    author VARCHAR(255)\n",
    ");'''\n",
    "\n",
    "create_poems_table = '''\n",
    "CREATE TABLE poetry.poems\n",
    "(\n",
    "    id serial PRIMARY KEY,\n",
    "    author VARCHAR(255),\n",
    "    linecount INT,\n",
    "    lines TEXT,\n",
    "    title VARCHAR(510)\n",
    ");\n",
    "'''\n",
    "    \n",
    "conn.execute(create_author_table)\n",
    "conn.execute(create_poems_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `psql` and `\\copy` to load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[`psql`](https://www.postgresql.org/docs/9.2/static/app-psql.html) is a Postgresql interactive terminal and is very useful for working with Postgresql databases and schemas. For those with a MySQL background, `psql` is quite similar to the `mysql` interactive terminal. The following is used to launch the `psql` terminal.\n",
    "\n",
    "```terminal\n",
    "psql -h localhost -U postgres postgres\n",
    "```\n",
    "\n",
    "Where the `-h` flag specifies the host to connect, which in this case is `localhost`. The `-U postgres` argument specifies the username `postgres` to use to connect to the `postgres` database. For those having issues launching the `psql` terminal, it is usually due to the command not being set in the PATH. Here is a good [StackOverflow](https://stackoverflow.com/questions/36155219/psql-command-not-found-mac) page that explains in detail how to add the `psql` command to the PATH on Mac.\n",
    "\n",
    "After launching `psql`, using the `\\dt` command will display the current tables and relations in the current schema.\n",
    "\n",
    "The `\\copy` command is used to insert data from a standard flat-file such as a csv into a schema table. The path to the data file to load into the table generally needs to be the absolute path. We specify the columns to insert the data within the parentheses to avoid accidentally inserting the rows into the schema table's `id` column, which acts as its `PRIMARY KEY`.\n",
    "\n",
    "```terminal\n",
    "\\copy poetry.authors(author) FROM '/Users/aaronschlegel/Dropbox/Projects/poetpy/data/poetrydb_authors.csv' DELIMITER ',' CSV HEADER;\n",
    "```\n",
    "\n",
    "```terminal\n",
    "\\copy poetry.poems(author, linecount, lines, title) FROM '/Users/aaronschlegel/Dropbox/Projects/poetpy/data/poetrydb_copy.csv' DELIMITER ',' CSV HEADER;\n",
    "```\n",
    "\n",
    "If the `\\copy` is successful, the terminal will output the number of rows that were inserted into the table. We can now perform queries on the tables!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using SQLAlchemy and pandas to load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `DataFrame` class has a handy method, [`to_sql`](https://pandas.pydata.org/pandas-docs/version/0.22/generated/pandas.DataFrame.to_sql.html) for inserting data into a SQL table directly. As we already created two tables earlier, we will give these a different name to identify the new tables created from the `DataFrame`. The name of the SQL table to insert into is designated by the first argument of the `to_sql` method, while the second required argument is a database connection string, just like the one we created previously with SQLAlchemy! To get a sequential `id` column inserted into the SQL table simultaneously, we will also specify that the `DataFrame` index column is named `id` with the optional `index_label` argument. We also want to be sure to set the `schema` optional argument to the `poetry` schema (since we are working with Postgresql) that we created earlier in the example. Otherwise, the tables will be created in the default `public` schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "poems_df.to_sql('poems_df', conn, schema='poetry', index_label='id')\n",
    "authors_df.to_sql('authors_df', conn, schema='poetry', index_label='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There were no errors or warnings issued. Therefore the data insertion should have been successful! In the next section, we perform some sample queries on the newly created SQL tables to ensure the data is what we expect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps unsurprisingly, there are multiple ways to query our Postgresql schema tables. The first is to use the `.execute()` method from our database connection variable `conn`, which we created earlier in the example. Let's say we are interested in finding the first 3 authors from the `author` table in our `poetry` schema. The SQL query can be written as:\n",
    "\n",
    "```sql\n",
    "SELECT author FROM poetry.authors LIMIT 3\n",
    "```\n",
    "\n",
    "The above query can be passed as an argument to the `.execute()` method as a string to query the database. The `.fetchall()` is chained to the end of the `.execute()` method to extract all the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Adam Lindsay Gordon',), ('Alan Seeger',), ('Alexander Pope',)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.execute('SELECT author FROM poetry.authors LIMIT 3').fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the statement returned the first three authors as a list of tuples as expected! More information on using SQL queries with SQLAlchemy can be found in [SQLAlchemy's tutorial](http://docs.sqlalchemy.org/en/latest/core/tutorial.html).\n",
    "\n",
    "Another method for querying a database that can be very useful is to use the `pandas` function [`read_sql_query`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_query.html). The function [`read_sql`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql.html#pandas.read_sql) can also be used to return the same results. The required arguments for the function are the query and a connection string. The benefit of using the `read_sql_query` function is the results are pulled directly into a pandas `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adam Lindsay Gordon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alan Seeger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alexander Pope</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               authors\n",
       "0  Adam Lindsay Gordon\n",
       "1          Alan Seeger\n",
       "2       Alexander Pope"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql_query('SELECT authors FROM poetry.authors_df LIMIT 3', conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we displayed a sample use case for extracting data from a database through an API and then using that data to create the database that we can use for further analysis and more without worrying about hitting the API database more than needed. In further examples, we will enhance the data we extracted from the API with more information collected from different sources and feature engineering on the already available data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About PoetryDB "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[PoetryDB](http://poetrydb.org/index.html) was created and is currently maintained by \n",
    "[@thundercomb](https://twitter.com/thundercomb). They blog about poetry and related technology and \n",
    "other topics at [thecombedthunderclap.blogspot.com](http://thecombedthunderclap.blogspot.com/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
